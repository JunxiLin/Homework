{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 数独问题\n",
    "\n",
    "* 林俊禧\n",
    "* 2022205222\n",
    "\n",
    "**任务简介**\n",
    "数独（Sudoku）是源自18世纪瑞士的一种数学游戏。是一种运用纸、笔进行演算的逻辑游戏。玩家需要根据9×9盘面上的已知数字，推理出所有剩余空格的数字，并满足每一行、每一列、每一个粗线宫（3*3）内的数字均含1-9，不重复。\n",
    "\n",
    "数独有空间特征，因为它有特殊的数字排列，而CNN擅长提取空间特征，可尝试使用CNN来求解数独。\n",
    "\n",
    "**数据简介**\n",
    "数据来源：https://www.kaggle.com/bryanpark/sudoku\n",
    "\n",
    "数据集包含2列。`quizzes`栏目是未解的游戏，`solutions`栏目各自的已解游戏。每场比赛都由81个数字组成的字符串表示。\n",
    "\n",
    "**要求**\n",
    "1. 分析数独游戏的特点，设计实现的方法。\n",
    "2. 在Kaggle网站上，下载数据。\n",
    "3. 编写神经网络代码，测试自己算法的效果如何。\n",
    "4. 测试所研究方法的效果。\n",
    "5. 分析自己实现的方法的问题，以及如何改进。\n",
    "6. 深入思考，如何使用强化学习的方法实现求解数独问题？"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**游戏特点**\n",
    "数独是一种流行的数字谜题，它要求玩家在9X9网格中填入数字，以便每一列、每一行和9个子网格中的每一个都包含从1到9的所有数字。在解决数独谜题时，玩家需要同时依赖网格上数字的位置和关系来作出填充的判断。受这些语义的启发，可以尝试使用CNN来解决数独难题。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "batch_size = 64\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "class DatasetInstance(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        sudoku = self.X[index]\n",
    "        target = self.y[index]\n",
    "        return sudoku,target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "def norm(data):\n",
    "    return (data/9)-0.5\n",
    "\n",
    "def get_data(file):\n",
    "    data = pd.read_csv(file)\n",
    "    quizzes_raw = data['quizzes']\n",
    "    solutions_raw = data['solutions']\n",
    "\n",
    "    quizzes = []\n",
    "    solutions = []\n",
    "\n",
    "    print(\"Loading Sudokus\")\n",
    "    for i in tqdm(quizzes_raw):\n",
    "        x = np.array([int(j) for j in i]).reshape((1,9,9))\n",
    "        quizzes.append(x)\n",
    "    quizzes = norm(np.array(quizzes))\n",
    "\n",
    "    print(\"Loading Solutions\")\n",
    "    for i in tqdm(solutions_raw):\n",
    "        x = np.array([int(j) for j in i]).reshape((9,9)) - 1\n",
    "        solutions.append(x)\n",
    "\n",
    "    solutions = np.array(solutions)\n",
    "\n",
    "    del quizzes_raw\n",
    "    del solutions_raw\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(quizzes, solutions, test_size=0.2, random_state=42)\n",
    "    X_train = torch.tensor(X_train).type(torch.FloatTensor)\n",
    "    X_test = torch.tensor(X_test).type(torch.FloatTensor)\n",
    "    y_train = torch.tensor(y_train).type(torch.LongTensor)\n",
    "    y_test = torch.tensor(y_test).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = DatasetInstance(X_train, y_train)\n",
    "    test_dataset = DatasetInstance(X_test, y_test)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sudokus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:10<00:00, 94349.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Solutions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:10<00:00, 95745.38it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = get_data('sudoku.csv')\n",
    "#convert to tensors\n",
    "\n",
    "# load training data in batches\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "class Conv2dLayer(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, bias=True, padding_layer=torch.nn.ReflectionPad2d):\n",
    "        \"\"\"It only support square kernels and stride=1, dilation=1, groups=1.\"\"\"\n",
    "        super(Conv2dLayer, self).__init__()\n",
    "        ka = kernel_size // 2\n",
    "        kb = ka - 1 if kernel_size % 2 == 0 else ka\n",
    "        self.net = nn.Sequential(\n",
    "            padding_layer((ka,kb,ka,kb)),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, bias=bias),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SudokuCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SudokuCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(Conv2dLayer(1,512,3), #1\n",
    "                                         Conv2dLayer(512,512,3),#2\n",
    "                                         Conv2dLayer(512,512,3),#3\n",
    "                                         Conv2dLayer(512,512,3),#4\n",
    "                                         Conv2dLayer(512,512,3),#5\n",
    "                                         Conv2dLayer(512,512,3),#6\n",
    "                                         Conv2dLayer(512,512,3),#7\n",
    "                                         Conv2dLayer(512,512,3),#8\n",
    "                                         Conv2dLayer(512,512,3),#9\n",
    "                                         Conv2dLayer(512,512,3),#10\n",
    "                                         Conv2dLayer(512,512,3),#11\n",
    "                                         Conv2dLayer(512,512,3),#12\n",
    "                                         Conv2dLayer(512,512,3),#13\n",
    "                                         Conv2dLayer(512,512,3),#14\n",
    "                                         Conv2dLayer(512,512,3))#15\n",
    "        self.last_conv = nn.Conv2d(512, 9, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.last_conv(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "net = SudokuCNN()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer =torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "min_loss = float('inf')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def train_net(epoch, n_epochs, net, criterion, optimizer, device, train_loader):\n",
    "\n",
    "    # prepare the net for training\n",
    "    net.train()\n",
    "\n",
    "    print(device)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # train on batches of data, assumes you already have train_loader\n",
    "    for batch_i, data in enumerate(train_loader):\n",
    "        # get the input  and their corresponding targets\n",
    "        sudoku = data[0]\n",
    "        target = data[1]\n",
    "        # zero the parameter (weight) gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sudoku = sudoku.to(device)\n",
    "        target = target.to(device)\n",
    "        sudoku = Variable(sudoku)\n",
    "        target = Variable(target)\n",
    "        # forward pass to get outputs\n",
    "        output = net(sudoku)\n",
    "\n",
    "        # calculate the loss between predicted and target\n",
    "        loss = criterion(output , target)\n",
    "\n",
    "        # backward pass to calculate the weight gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # print loss statistics\n",
    "        running_loss += loss.item()\n",
    "        if batch_i % 200 == 0:    # print every 10 batches\n",
    "            print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, running_loss/10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    #print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def val_net(epoch, n_epochs, net, criterion, optimizer, device, test_loader):\n",
    "    net.eval()\n",
    "    val_loss=0.0\n",
    "    print(device)\n",
    "    correct = 0\n",
    "    ndata = 0\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i,data in enumerate(test_loader):\n",
    "            sudoku = data[0]\n",
    "            target = data[1]\n",
    "            optimizer.zero_grad()\n",
    "            sudoku = sudoku.to(device)\n",
    "            target = target.to(device)\n",
    "            # forward pass to get outputs\n",
    "            output = net(sudoku)\n",
    "\n",
    "            # calculate the loss between predicted and target\n",
    "            loss = criterion(output , target)\n",
    "\n",
    "            val_loss+=loss.data.item()\n",
    "            preds = torch.argmax(output,dim=1)\n",
    "\n",
    "            for j in range(len(preds)):\n",
    "                if (preds[j] == target[j]).all():\n",
    "                    correct += 1\n",
    "            ndata += preds.shape[0]\n",
    "            if i==0 or i % 1000 == 0:\n",
    "                print(f'Test Loss at {i}: {val_loss / (i + 1)} Accuracy:{correct}/{ndata}')\n",
    "    print(f'Test Loss at {i}: {val_loss / (i + 1)} Accuracy:{correct/ndata}')\n",
    "    return val_loss / (i + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Training=======\n",
      "cpu\n",
      "Epoch: 1, Batch: 1, Avg. Loss: 0.2247058391571045\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(\"=====Training=======\")\n",
    "    train_net(epoch, n_epochs, net, criterion, optimizer, device, train_loader)\n",
    "    print(\"=====Validation=======\")\n",
    "    loss = val_net(epoch, n_epochs, net, criterion, optimizer, device, test_loader)\n",
    "    if loss < min_loss:\n",
    "        print(\"=====Saving=======\")\n",
    "        model_dir = './saved_models/'\n",
    "        name = 'SudokuCNN.pt'\n",
    "        min_loss = loss\n",
    "        torch.save(net.state_dict(), model_dir+name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def denorm(a):\n",
    "\n",
    "    return (a+.5)*9\n",
    "\n",
    "def inference_sudoku(sample,model):\n",
    "\n",
    "    '''\n",
    "        This function solve the sudoku by filling blank positions one by one.\n",
    "    '''\n",
    "\n",
    "    feat = sample.clone().cuda()\n",
    "\n",
    "    while True:\n",
    "\n",
    "        out = model(feat.reshape((1,1,9,9)))\n",
    "\n",
    "        pred = torch.argmax(out, axis=1).reshape((9,9)) + 1\n",
    "        prob,_ = torch.max(out, axis=1)\n",
    "        #prob = prob.reshape((9,9))\n",
    "        feat = denorm(feat).reshape((9,9))\n",
    "        mask = (feat==0)\n",
    "\n",
    "        if(mask.sum()==0):\n",
    "            break\n",
    "        prob = torch.sigmoid(prob)\n",
    "        prob_new = prob.flatten() * mask.flatten()\n",
    "\n",
    "        ind = torch.argmax(prob_new)\n",
    "        x, y = (ind//9), (ind%9)\n",
    "\n",
    "        val = pred[x][y]\n",
    "        feat[x][y] = val\n",
    "        feat = norm(feat)\n",
    "    return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test_accuracy(epoch, n_epochs, net, device, test_loader):\n",
    "    net.eval()\n",
    "    print(device)\n",
    "    correct = 0\n",
    "    ndata = 0\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i,data in enumerate(test_loader):\n",
    "            sudoku = data[0]\n",
    "            target = data[1]\n",
    "            sudoku = sudoku.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "\n",
    "            for j in range(len(sudoku)):\n",
    "                if (inference_sudoku(sudoku[j],net) == target[j] + 1).all():\n",
    "                    correct += 1\n",
    "\n",
    "            ndata += sudoku.shape[0]\n",
    "            if ndata>=1000:\n",
    "                print(f' Accuracy:{correct}/{ndata}')\n",
    "    print(f'Final Accuracy:{correct/ndata}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_accuracy(0, 0, net, device, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
